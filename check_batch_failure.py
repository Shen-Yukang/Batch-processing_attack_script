#!/usr/bin/env python3
"""
æ£€æŸ¥OpenAIæ‰¹å¤„ç†å¤±è´¥çš„åŸå› 
"""

import os
import json
import logging
import openai

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_batch_failure():
    """æ£€æŸ¥æœ€è¿‘å¤±è´¥çš„æ‰¹å¤„ç†"""
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        logger.error("âŒ OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        return
    
    client = openai.OpenAI(api_key=api_key)
    
    try:
        # è·å–æœ€è¿‘çš„æ‰¹å¤„ç†åˆ—è¡¨
        logger.info("ğŸ” è·å–æœ€è¿‘çš„æ‰¹å¤„ç†åˆ—è¡¨...")
        batches = client.batches.list(limit=10)
        
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(batches.data)} ä¸ªæœ€è¿‘çš„æ‰¹å¤„ç†")
        
        failed_batches = []
        for batch in batches.data:
            logger.info(f"ğŸ“„ æ‰¹å¤„ç† {batch.id}:")
            logger.info(f"   çŠ¶æ€: {batch.status}")
            logger.info(f"   åˆ›å»ºæ—¶é—´: {batch.created_at}")
            
            if batch.status == 'failed':
                failed_batches.append(batch)
                logger.error(f"âŒ å¤±è´¥çš„æ‰¹å¤„ç†: {batch.id}")
                
                # è·å–è¯¦ç»†ä¿¡æ¯
                try:
                    detailed_batch = client.batches.retrieve(batch.id)
                    logger.info(f"   å¤±è´¥æ—¶é—´: {detailed_batch.failed_at}")
                    
                    # æ£€æŸ¥é”™è¯¯æ–‡ä»¶
                    if detailed_batch.error_file_id:
                        logger.info(f"   é”™è¯¯æ–‡ä»¶ID: {detailed_batch.error_file_id}")
                        
                        try:
                            error_content = client.files.content(detailed_batch.error_file_id)
                            error_text = error_content.content.decode('utf-8')
                            logger.error(f"   é”™è¯¯å†…å®¹: {error_text[:500]}...")
                        except Exception as e:
                            logger.warning(f"   æ— æ³•è¯»å–é”™è¯¯æ–‡ä»¶: {e}")
                    
                    # æ£€æŸ¥è¯·æ±‚ç»Ÿè®¡
                    if detailed_batch.request_counts:
                        counts = detailed_batch.request_counts
                        logger.info(f"   è¯·æ±‚ç»Ÿè®¡:")
                        logger.info(f"     æ€»æ•°: {getattr(counts, 'total', 0)}")
                        logger.info(f"     å®Œæˆ: {getattr(counts, 'completed', 0)}")
                        logger.info(f"     å¤±è´¥: {getattr(counts, 'failed', 0)}")
                        
                except Exception as e:
                    logger.error(f"   è·å–è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
            
            elif batch.status == 'completed':
                logger.info(f"âœ… æˆåŠŸçš„æ‰¹å¤„ç†: {batch.id}")
                if batch.output_file_id:
                    logger.info(f"   è¾“å‡ºæ–‡ä»¶ID: {batch.output_file_id}")
        
        if not failed_batches:
            logger.info("âœ… æ²¡æœ‰å‘ç°å¤±è´¥çš„æ‰¹å¤„ç†")
        else:
            logger.warning(f"âš ï¸  å‘ç° {len(failed_batches)} ä¸ªå¤±è´¥çš„æ‰¹å¤„ç†")
            
    except Exception as e:
        logger.error(f"âŒ æ£€æŸ¥æ‰¹å¤„ç†å¤±è´¥: {e}")

def check_input_file_format(file_path):
    """æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ ¼å¼"""
    logger.info(f"ğŸ” æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ ¼å¼: {file_path}")
    
    if not os.path.exists(file_path):
        logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        logger.info(f"ğŸ“Š æ–‡ä»¶åŒ…å« {len(lines)} è¡Œ")
        
        # æ£€æŸ¥å‰å‡ è¡Œçš„æ ¼å¼
        for i, line in enumerate(lines[:3], 1):
            try:
                data = json.loads(line.strip())
                logger.info(f"âœ… ç¬¬{i}è¡Œæ ¼å¼æ­£ç¡®")
                
                # æ£€æŸ¥å¿…è¦å­—æ®µ
                required_fields = ['custom_id', 'method', 'url', 'body']
                missing_fields = [field for field in required_fields if field not in data]
                
                if missing_fields:
                    logger.error(f"âŒ ç¬¬{i}è¡Œç¼ºå°‘å­—æ®µ: {missing_fields}")
                else:
                    logger.info(f"âœ… ç¬¬{i}è¡ŒåŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µ")
                
                # æ£€æŸ¥bodyå†…å®¹
                body = data.get('body', {})
                if 'model' not in body:
                    logger.error(f"âŒ ç¬¬{i}è¡Œbodyä¸­ç¼ºå°‘modelå­—æ®µ")
                if 'messages' not in body:
                    logger.error(f"âŒ ç¬¬{i}è¡Œbodyä¸­ç¼ºå°‘messageså­—æ®µ")
                
                # æ£€æŸ¥å›¾ç‰‡å¤§å°
                messages = body.get('messages', [])
                for msg in messages:
                    content = msg.get('content', [])
                    if isinstance(content, list):
                        for item in content:
                            if item.get('type') == 'image_url':
                                image_url = item.get('image_url', {}).get('url', '')
                                if image_url.startswith('data:image'):
                                    # ä¼°ç®—base64å›¾ç‰‡å¤§å°
                                    base64_data = image_url.split(',')[1] if ',' in image_url else ''
                                    size_mb = len(base64_data) * 3 / 4 / 1024 / 1024
                                    logger.info(f"ğŸ“· ç¬¬{i}è¡Œå›¾ç‰‡å¤§å°çº¦: {size_mb:.2f} MB")
                                    
                                    if size_mb > 20:
                                        logger.warning(f"âš ï¸  ç¬¬{i}è¡Œå›¾ç‰‡å¯èƒ½è¿‡å¤§ ({size_mb:.2f} MB > 20 MB)")
                
            except json.JSONDecodeError as e:
                logger.error(f"âŒ ç¬¬{i}è¡ŒJSONæ ¼å¼é”™è¯¯: {e}")
            except Exception as e:
                logger.error(f"âŒ ç¬¬{i}è¡Œæ£€æŸ¥å¤±è´¥: {e}")
                
    except Exception as e:
        logger.error(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")

def check_api_quota():
    """æ£€æŸ¥APIé…é¢"""
    logger.info("ğŸ” æ£€æŸ¥APIé…é¢å’Œæ¨¡å‹å¯ç”¨æ€§...")
    
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        logger.error("âŒ OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        return
    
    client = openai.OpenAI(api_key=api_key)
    
    try:
        # æ£€æŸ¥å¯ç”¨æ¨¡å‹
        models = client.models.list()
        available_models = [model.id for model in models.data if 'gpt-4' in model.id]
        logger.info(f"âœ… å¯ç”¨çš„GPT-4æ¨¡å‹: {available_models}")
        
        # å°è¯•ç®€å•çš„APIè°ƒç”¨
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": "Hello"}],
            max_tokens=5
        )
        logger.info("âœ… APIè°ƒç”¨æµ‹è¯•æˆåŠŸ")
        
    except Exception as e:
        logger.error(f"âŒ APIæ£€æŸ¥å¤±è´¥: {e}")
        if "quota" in str(e).lower():
            logger.error("ğŸ’° å¯èƒ½æ˜¯é…é¢ä¸è¶³é—®é¢˜")
        elif "rate" in str(e).lower():
            logger.error("ğŸš¦ å¯èƒ½æ˜¯é€Ÿç‡é™åˆ¶é—®é¢˜")

def main():
    logger.info("ğŸ”§ OpenAIæ‰¹å¤„ç†å¤±è´¥è¯Šæ–­å·¥å…·")
    logger.info("="*60)
    
    # æ£€æŸ¥APIé…é¢
    check_api_quota()
    
    print()
    
    # æ£€æŸ¥æ‰¹å¤„ç†å†å²
    check_batch_failure()
    
    print()
    
    # æ£€æŸ¥æœ€è¿‘çš„è¾“å…¥æ–‡ä»¶
    input_file = "output/batch_results_content_Jailbreak28k_20250526_100028/batch_001.jsonl"
    if os.path.exists(input_file):
        check_input_file_format(input_file)
    else:
        logger.warning(f"âš ï¸  è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")

if __name__ == "__main__":
    main()
