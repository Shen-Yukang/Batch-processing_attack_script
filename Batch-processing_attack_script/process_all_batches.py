#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–å¤„ç†æ‰€æœ‰æ‰¹æ¬¡çš„è„šæœ¬
"""

import os
import time
import logging
import subprocess
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def run_command(command, description):
    """è¿è¡Œå‘½ä»¤å¹¶è®°å½•ç»“æœ"""
    logger.info(f"æ‰§è¡Œ: {description}")
    logger.info(f"å‘½ä»¤: {command}")
    
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        
        if result.returncode == 0:
            logger.info(f"âœ… {description} æˆåŠŸ")
            if result.stdout:
                logger.info(f"è¾“å‡º: {result.stdout.strip()}")
            return True
        else:
            logger.error(f"âŒ {description} å¤±è´¥")
            logger.error(f"é”™è¯¯: {result.stderr.strip()}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ {description} å¼‚å¸¸: {e}")
        return False

def create_batch_configs():
    """å®šä¹‰æ‰¹æ¬¡é…ç½®"""
    return [
        {"name": "batch1", "start": 0, "end": 30},
        {"name": "batch2", "start": 30, "end": 60},
        {"name": "batch3", "start": 60, "end": 90},
        {"name": "batch4", "start": 90, "end": 120},
        {"name": "batch5", "start": 120, "end": 150},
        {"name": "batch6", "start": 150, "end": 172},
    ]

def process_all_batches():
    """å¤„ç†æ‰€æœ‰æ‰¹æ¬¡"""
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        logger.error("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
        return False
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    input_csv = "new_csv/content_CogAgent.csv"
    if not os.path.exists(input_csv):
        logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_csv}")
        return False
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = f"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    os.makedirs(output_dir, exist_ok=True)
    logger.info(f"åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
    
    # è·å–æ‰¹æ¬¡é…ç½®
    batches = create_batch_configs()
    
    logger.info("=" * 80)
    logger.info(f"å¼€å§‹å¤„ç† {len(batches)} ä¸ªæ‰¹æ¬¡")
    logger.info("=" * 80)
    
    successful_batches = []
    failed_batches = []
    
    for i, batch_config in enumerate(batches, 1):
        batch_name = batch_config["name"]
        start_row = batch_config["start"]
        end_row = batch_config["end"]
        
        logger.info(f"\nğŸ“¦ å¤„ç†æ‰¹æ¬¡ {i}/{len(batches)}: {batch_name}")
        logger.info(f"è¡ŒèŒƒå›´: {start_row+1}-{end_row}")
        
        # æ­¥éª¤1: åˆ›å»ºæ‰¹å¤„ç†è¾“å…¥æ–‡ä»¶
        jsonl_file = os.path.join(output_dir, f"{batch_name}.jsonl")
        create_cmd = f"python create_safe_batch_input.py {input_csv} {jsonl_file} --model gpt-4o-mini --start-row {start_row} --end-row {end_row}"
        
        if not run_command(create_cmd, f"åˆ›å»º {batch_name} è¾“å…¥æ–‡ä»¶"):
            failed_batches.append(batch_name)
            continue
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åˆ›å»ºæˆåŠŸ
        if not os.path.exists(jsonl_file):
            logger.error(f"âŒ {batch_name} è¾“å…¥æ–‡ä»¶æœªåˆ›å»º")
            failed_batches.append(batch_name)
            continue
        
        # æ­¥éª¤2: æäº¤æ‰¹å¤„ç†
        process_cmd = f"python batch_processor.py {jsonl_file} --output-dir {output_dir}"
        
        if run_command(process_cmd, f"å¤„ç† {batch_name} æ‰¹æ¬¡"):
            successful_batches.append(batch_name)
            logger.info(f"âœ… {batch_name} æ‰¹æ¬¡å®Œæˆ")
        else:
            failed_batches.append(batch_name)
            logger.error(f"âŒ {batch_name} æ‰¹æ¬¡å¤±è´¥")
        
        # åœ¨æ‰¹æ¬¡ä¹‹é—´æ·»åŠ å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
        if i < len(batches):
            logger.info("ç­‰å¾…30ç§’åå¤„ç†ä¸‹ä¸€ä¸ªæ‰¹æ¬¡...")
            time.sleep(30)
    
    # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    logger.info("=" * 80)
    logger.info("æ‰¹å¤„ç†å®Œæˆæ€»ç»“")
    logger.info("=" * 80)
    logger.info(f"æˆåŠŸæ‰¹æ¬¡ ({len(successful_batches)}): {', '.join(successful_batches)}")
    
    if failed_batches:
        logger.warning(f"å¤±è´¥æ‰¹æ¬¡ ({len(failed_batches)}): {', '.join(failed_batches)}")
        logger.info("å¯ä»¥æ‰‹åŠ¨é‡è¯•å¤±è´¥çš„æ‰¹æ¬¡")
    
    # å¦‚æœæœ‰æˆåŠŸçš„æ‰¹æ¬¡ï¼Œæä¾›åˆå¹¶æŒ‡ä»¤
    if successful_batches:
        logger.info("\nğŸ“‹ ä¸‹ä¸€æ­¥: åˆå¹¶ç»“æœ")
        logger.info("ç­‰æ‰€æœ‰æ‰¹æ¬¡å®Œæˆåï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤åˆå¹¶ç»“æœ:")
        logger.info(f"python merge_all_results.py {output_dir} {input_csv} final_output.csv")
    
    return len(failed_batches) == 0

def main():
    logger.info("ğŸš€ å¼€å§‹è‡ªåŠ¨åŒ–æ‰¹å¤„ç†å·¥ä½œæµç¨‹")
    
    success = process_all_batches()
    
    if success:
        logger.info("ğŸ‰ æ‰€æœ‰æ‰¹æ¬¡å¤„ç†æˆåŠŸï¼")
    else:
        logger.warning("âš ï¸ éƒ¨åˆ†æ‰¹æ¬¡å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

if __name__ == "__main__":
    main()
