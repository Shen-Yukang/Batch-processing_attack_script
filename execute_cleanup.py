#!/usr/bin/env python3
"""
æ‰§è¡Œé¡¹ç›®æ¸…ç†è„šæœ¬
å®‰å…¨åœ°æ¸…ç†å’Œé‡ç»„é¡¹ç›®ç›®å½•ç»“æ„
"""

import os
import shutil
import glob
from pathlib import Path
import logging
import json
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ProjectCleanupExecutor:
    def __init__(self, project_root=".", dry_run=True):
        self.project_root = Path(project_root)
        self.dry_run = dry_run
        self.cleanup_log = []
        
        # æ ¸å¿ƒæ–‡ä»¶åˆ—è¡¨ï¼ˆç»å¯¹ä¸èƒ½åˆ é™¤ï¼‰
        self.core_files = {
            "batch_processor.py",
            "robust_batch_processor.py", 
            "cost_tracker.py",
            "create_safe_batch_input.py",
            "process_batch_results.py",
            "batch_workflow.py",
            "resume_batch_processing.py",
            "quick_test.py",
            "view_costs.py",
            "requirements.txt",
            "README.md",
            "BATCH_GUIDE.md",
            "batch_config.conf"
        }
        
        # å¯é€‰ä¿ç•™æ–‡ä»¶
        self.optional_files = {
            "create_batch_input.py",  # åŠŸèƒ½ä¸create_safe_batch_input.pyé‡å¤
            "process_csv_with_chatgpt.py",  # å®æ—¶å¤„ç†åŠŸèƒ½
            "batch_process.py"  # ç®€å•æ‰¹å¤„ç†è„šæœ¬
        }
        
        # æ•°æ®æ–‡ä»¶ï¼ˆç§»åŠ¨åˆ°dataç›®å½•ï¼‰
        self.data_files = {
            "_csvs/content_FigStep.csv",
            "_csvs/content_Jailbreak28k.csv", 
            "_csvs/content_MMSafeBench_cleaned.csv"
        }
    
    def log_action(self, action, file_path, status="planned"):
        """è®°å½•æ¸…ç†åŠ¨ä½œ"""
        self.cleanup_log.append({
            "timestamp": datetime.now().isoformat(),
            "action": action,
            "file": str(file_path),
            "status": status
        })
    
    def safe_delete(self, file_path):
        """å®‰å…¨åˆ é™¤æ–‡ä»¶æˆ–ç›®å½•"""
        try:
            if self.dry_run:
                logger.info(f"[DRY RUN] å°†åˆ é™¤: {file_path}")
                self.log_action("delete", file_path, "dry_run")
                return True
            
            if os.path.isdir(file_path):
                shutil.rmtree(file_path)
                logger.info(f"ğŸ—‘ï¸  åˆ é™¤ç›®å½•: {file_path}")
            else:
                os.remove(file_path)
                logger.info(f"ğŸ—‘ï¸  åˆ é™¤æ–‡ä»¶: {file_path}")
            
            self.log_action("delete", file_path, "completed")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤å¤±è´¥ {file_path}: {e}")
            self.log_action("delete", file_path, f"failed: {e}")
            return False
    
    def safe_move(self, src, dst):
        """å®‰å…¨ç§»åŠ¨æ–‡ä»¶"""
        try:
            if self.dry_run:
                logger.info(f"[DRY RUN] å°†ç§»åŠ¨: {src} -> {dst}")
                self.log_action("move", f"{src} -> {dst}", "dry_run")
                return True
            
            # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(dst), exist_ok=True)
            shutil.move(src, dst)
            logger.info(f"ğŸ“¦ ç§»åŠ¨: {src} -> {dst}")
            self.log_action("move", f"{src} -> {dst}", "completed")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç§»åŠ¨å¤±è´¥ {src} -> {dst}: {e}")
            self.log_action("move", f"{src} -> {dst}", f"failed: {e}")
            return False
    
    def clean_redundant_scripts(self):
        """æ¸…ç†å†—ä½™è„šæœ¬"""
        logger.info("ğŸ§¹ æ¸…ç†å†—ä½™è„šæœ¬...")
        
        # è·å–æ‰€æœ‰Pythonæ–‡ä»¶
        all_py_files = set(glob.glob(str(self.project_root / "*.py")))
        
        # æ’é™¤æ ¸å¿ƒæ–‡ä»¶å’Œå¯é€‰æ–‡ä»¶
        core_paths = {str(self.project_root / f) for f in self.core_files if f.endswith('.py')}
        optional_paths = {str(self.project_root / f) for f in self.optional_files}
        
        # è¦åˆ é™¤çš„æ–‡ä»¶
        files_to_delete = all_py_files - core_paths - optional_paths
        
        # é¢å¤–æ’é™¤ä¸€äº›é‡è¦æ–‡ä»¶
        important_patterns = [
            "*cleanup*.py",  # æ¸…ç†è„šæœ¬æœ¬èº«
            "*analyze*.py"   # åˆ†æè„šæœ¬
        ]
        
        for pattern in important_patterns:
            important_files = set(glob.glob(str(self.project_root / pattern)))
            files_to_delete -= important_files
        
        deleted_count = 0
        for file_path in files_to_delete:
            if self.safe_delete(file_path):
                deleted_count += 1
        
        logger.info(f"âœ… æ¸…ç†äº† {deleted_count} ä¸ªå†—ä½™è„šæœ¬")
    
    def clean_output_files(self):
        """æ¸…ç†è¾“å‡ºæ–‡ä»¶"""
        logger.info("ğŸ§¹ æ¸…ç†è¾“å‡ºæ–‡ä»¶...")
        
        # æ—§çš„æ‰¹å¤„ç†ç»“æœç›®å½•
        old_batch_dirs = glob.glob(str(self.project_root / "batch_results_*"))
        
        # ä¸´æ—¶CSVæ–‡ä»¶
        temp_csvs = [
            "current_status.csv",
            "new_output.csv",
            "output.csv", 
            "final_output*.csv",
            "complete_final_output.csv",
            "quick_test_result.csv",
            "resume_data_*.csv"
        ]
        
        # ä¸´æ—¶æ–‡ä»¶
        temp_files = []
        for pattern in temp_csvs:
            temp_files.extend(glob.glob(str(self.project_root / pattern)))
        
        # JSONLæ–‡ä»¶
        temp_files.extend(glob.glob(str(self.project_root / "*.jsonl")))
        
        # JSONæŠ¥å‘Šæ–‡ä»¶
        temp_files.extend(glob.glob(str(self.project_root / "batch_analysis_*.json")))
        
        # æ–‡æœ¬æ–‡ä»¶
        temp_files.extend(glob.glob(str(self.project_root / "*missing_rows*.txt")))
        
        # åˆ é™¤æ–‡ä»¶
        deleted_count = 0
        for file_path in old_batch_dirs + temp_files:
            if self.safe_delete(file_path):
                deleted_count += 1
        
        logger.info(f"âœ… æ¸…ç†äº† {deleted_count} ä¸ªè¾“å‡ºæ–‡ä»¶")
    
    def clean_redundant_docs(self):
        """æ¸…ç†å†—ä½™æ–‡æ¡£"""
        logger.info("ğŸ§¹ æ¸…ç†å†—ä½™æ–‡æ¡£...")
        
        redundant_docs = [
            "AUTO_BATCH_GUIDE.md",
            "ENHANCED_PROCESSOR_GUIDE.md",
            "COMPLETE_EXECUTION_GUIDE.md", 
            "missing_rows_guide.md"
        ]
        
        deleted_count = 0
        for doc in redundant_docs:
            doc_path = self.project_root / doc
            if doc_path.exists() and self.safe_delete(doc_path):
                deleted_count += 1
        
        logger.info(f"âœ… æ¸…ç†äº† {deleted_count} ä¸ªå†—ä½™æ–‡æ¡£")
    
    def organize_data_files(self):
        """æ•´ç†æ•°æ®æ–‡ä»¶"""
        logger.info("ğŸ“ æ•´ç†æ•°æ®æ–‡ä»¶...")
        
        # åˆ›å»ºdataç›®å½•ç»“æ„
        data_dir = self.project_root / "data"
        input_dir = data_dir / "input"
        
        if not self.dry_run:
            input_dir.mkdir(parents=True, exist_ok=True)
        
        # ç§»åŠ¨CSVæ–‡ä»¶
        csv_dir = self.project_root / "_csvs"
        if csv_dir.exists():
            csv_files = glob.glob(str(csv_dir / "*.csv"))
            moved_count = 0
            
            for csv_file in csv_files:
                filename = os.path.basename(csv_file)
                dst = input_dir / filename
                if self.safe_move(csv_file, dst):
                    moved_count += 1
            
            # åˆ é™¤ç©ºçš„_csvsç›®å½•
            if not self.dry_run and not os.listdir(csv_dir):
                self.safe_delete(csv_dir)
            
            logger.info(f"âœ… ç§»åŠ¨äº† {moved_count} ä¸ªCSVæ–‡ä»¶åˆ° data/input/")
    
    def organize_output_directory(self):
        """æ•´ç†è¾“å‡ºç›®å½•"""
        logger.info("ğŸ“ æ•´ç†è¾“å‡ºç›®å½•...")
        
        output_dir = self.project_root / "output"
        if output_dir.exists():
            # åˆ›å»ºå­ç›®å½•
            subdirs = ["results", "logs", "temp"]
            
            for subdir in subdirs:
                subdir_path = output_dir / subdir
                if not self.dry_run:
                    subdir_path.mkdir(exist_ok=True)
                logger.info(f"ğŸ“ ç¡®ä¿ç›®å½•å­˜åœ¨: output/{subdir}/")
    
    def create_new_structure_summary(self):
        """åˆ›å»ºæ–°ç»“æ„æ‘˜è¦"""
        summary = {
            "cleanup_date": datetime.now().isoformat(),
            "dry_run": self.dry_run,
            "actions_performed": self.cleanup_log,
            "recommended_structure": {
                "core_files": list(self.core_files),
                "optional_files": list(self.optional_files),
                "directories": {
                    "data/input/": "è¾“å…¥CSVæ–‡ä»¶",
                    "output/results/": "æ‰¹å¤„ç†ç»“æœ",
                    "output/logs/": "æ—¥å¿—æ–‡ä»¶", 
                    "output/temp/": "ä¸´æ—¶æ–‡ä»¶"
                }
            }
        }
        
        summary_file = self.project_root / "CLEANUP_EXECUTION_LOG.json"
        
        if not self.dry_run:
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“„ æ¸…ç†æ‰§è¡Œæ—¥å¿—: {summary_file}")
    
    def execute_cleanup(self):
        """æ‰§è¡Œå®Œæ•´æ¸…ç†"""
        mode = "DRY RUN" if self.dry_run else "EXECUTION"
        logger.info(f"ğŸš€ å¼€å§‹é¡¹ç›®æ¸…ç† ({mode})...")
        
        if self.dry_run:
            logger.info("âš ï¸  è¿™æ˜¯é¢„è§ˆæ¨¡å¼ï¼Œä¸ä¼šå®é™…åˆ é™¤æ–‡ä»¶")
            logger.info("âš ï¸  è¦æ‰§è¡Œå®é™…æ¸…ç†ï¼Œè¯·ä½¿ç”¨ --execute å‚æ•°")
        
        # æ‰§è¡Œæ¸…ç†æ­¥éª¤
        self.clean_redundant_scripts()
        self.clean_output_files() 
        self.clean_redundant_docs()
        self.organize_data_files()
        self.organize_output_directory()
        
        # åˆ›å»ºæ‘˜è¦
        self.create_new_structure_summary()
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_actions = len(self.cleanup_log)
        logger.info("=" * 60)
        logger.info(f"ğŸ“Š æ¸…ç†å®Œæˆ ({mode})")
        logger.info("=" * 60)
        logger.info(f"æ€»è®¡æ“ä½œ: {total_actions} ä¸ª")
        
        if self.dry_run:
            logger.info("ğŸ”§ è¦æ‰§è¡Œå®é™…æ¸…ç†ï¼Œè¯·è¿è¡Œ:")
            logger.info("   python execute_cleanup.py --execute")
        else:
            logger.info("âœ… é¡¹ç›®æ¸…ç†å®Œæˆï¼")
            logger.info("ğŸ“‹ è¯·æŸ¥çœ‹ CLEANUP_EXECUTION_LOG.json äº†è§£è¯¦ç»†ä¿¡æ¯")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='æ‰§è¡Œé¡¹ç›®æ¸…ç†')
    parser.add_argument('--execute', action='store_true', 
                       help='æ‰§è¡Œå®é™…æ¸…ç†ï¼ˆé»˜è®¤ä¸ºé¢„è§ˆæ¨¡å¼ï¼‰')
    
    args = parser.parse_args()
    
    executor = ProjectCleanupExecutor(dry_run=not args.execute)
    executor.execute_cleanup()

if __name__ == "__main__":
    main()
