#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆç¼ºå¤±è¡Œé‡è¯•è„šæœ¬ - åŒ…å«è¯¦ç»†çš„å®æ—¶æ—¥å¿—è¾“å‡º
"""

import os
import sys
import logging
from datetime import datetime

def setup_enhanced_logging():
    """è®¾ç½®å¢å¼ºçš„æ—¥å¿—è®°å½•"""
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = os.path.join(log_dir, f"enhanced_retry_{timestamp}.log")
    
    # é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG)
    
    # æ¸…é™¤ç°æœ‰çš„handlers
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
    
    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    detailed_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
    )
    simple_formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # æ–‡ä»¶handler - è®°å½•æ‰€æœ‰è¯¦ç»†ä¿¡æ¯
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(detailed_formatter)
    root_logger.addHandler(file_handler)
    
    # æ§åˆ¶å°handler - æ˜¾ç¤ºé‡è¦ä¿¡æ¯
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(simple_formatter)
    root_logger.addHandler(console_handler)
    
    # åˆ›å»ºä¸“é—¨çš„è¿›åº¦logger
    progress_logger = logging.getLogger('progress')
    progress_handler = logging.StreamHandler(sys.stdout)
    progress_handler.setLevel(logging.INFO)
    progress_handler.setFormatter(logging.Formatter('%(message)s'))
    progress_logger.addHandler(progress_handler)
    progress_logger.propagate = False
    
    print(f"ğŸ“ è¯¦ç»†æ—¥å¿—å°†ä¿å­˜åˆ°: {log_file}")
    print(f"ğŸ–¥ï¸  æ§åˆ¶å°æ˜¾ç¤ºé‡è¦è¿›åº¦ä¿¡æ¯")
    print(f"ğŸ” å¦‚éœ€æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶")
    print("="*80)
    
    return logging.getLogger(__name__)

def check_environment():
    """æ£€æŸ¥æ‰§è¡Œç¯å¢ƒ"""
    logger = logging.getLogger(__name__)
    
    logger.info("ğŸ” æ£€æŸ¥æ‰§è¡Œç¯å¢ƒ...")
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    required_files = [
        'retry_missing_rows.py',
        'robust_batch_processor.py',
        'batch_processor.py',
        'missing_rows.txt',
        '_csvs/content_MMSafeBench_cleaned.csv'
    ]
    
    missing_files = []
    for file_path in required_files:
        if not os.path.exists(file_path):
            missing_files.append(file_path)
        else:
            logger.debug(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {file_path}")
    
    if missing_files:
        logger.error(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {missing_files}")
        return False
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        logger.error("âŒ æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return False
    elif not api_key.startswith('sk-'):
        logger.error("âŒ APIå¯†é’¥æ ¼å¼ä¸æ­£ç¡®")
        return False
    else:
        logger.info("âœ… APIå¯†é’¥å·²è®¾ç½®")
    
    # æ£€æŸ¥æ‰¹å¤„ç†ç›®å½•
    batch_dir = "batch_results_20250525_182528"
    if not os.path.exists(batch_dir):
        logger.error(f"âŒ æ‰¹å¤„ç†ç›®å½•ä¸å­˜åœ¨: {batch_dir}")
        return False
    else:
        logger.info(f"âœ… æ‰¹å¤„ç†ç›®å½•å­˜åœ¨: {batch_dir}")
    
    # æ£€æŸ¥ç¼ºå¤±è¡Œæ–‡ä»¶
    try:
        with open('missing_rows.txt', 'r') as f:
            lines = f.readlines()
        missing_count = len([line for line in lines if line.strip().isdigit()])
        logger.info(f"âœ… ç¼ºå¤±è¡Œæ–‡ä»¶åŒ…å« {missing_count} ä¸ªç¼ºå¤±è¡Œ")
    except Exception as e:
        logger.error(f"âŒ è¯»å–ç¼ºå¤±è¡Œæ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    logger.info("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
    return True

def show_execution_plan():
    """æ˜¾ç¤ºæ‰§è¡Œè®¡åˆ’"""
    logger = logging.getLogger(__name__)
    
    logger.info("ğŸ“‹ æ‰§è¡Œè®¡åˆ’:")
    logger.info("  1. è¯»å–ç¼ºå¤±è¡Œæ–‡ä»¶ (missing_rows.txt)")
    logger.info("  2. æ™ºèƒ½åˆ†ç»„ç¼ºå¤±è¡Œä¸ºæ‰¹æ¬¡")
    logger.info("  3. ä¸ºæ¯ä¸ªæ‰¹æ¬¡åˆ›å»ºè¾“å…¥æ–‡ä»¶")
    logger.info("  4. æäº¤åˆ°OpenAIæ‰¹å¤„ç†API")
    logger.info("  5. ç›‘æ§æ‰§è¡ŒçŠ¶æ€")
    logger.info("  6. ä¸‹è½½ç»“æœæ–‡ä»¶")
    logger.info("  7. æ›´æ–°çŠ¶æ€å’Œæˆæœ¬ç»Ÿè®¡")
    
    logger.info("ğŸ”§ é…ç½®å‚æ•°:")
    logger.info("  - CSVæ–‡ä»¶: _csvs/content_MMSafeBench_cleaned.csv")
    logger.info("  - æ‰¹å¤„ç†ç›®å½•: batch_results_20250525_182528")
    logger.info("  - æ‰¹æ¬¡å¤§å°: 20è¡Œ/æ‰¹æ¬¡")
    logger.info("  - æ‰¹æ¬¡é—´å»¶è¿Ÿ: 60ç§’")
    logger.info("  - æ¨¡å‹: gpt-4o-mini")

def run_enhanced_retry():
    """è¿è¡Œå¢å¼ºç‰ˆé‡è¯•"""
    logger = logging.getLogger(__name__)
    
    logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œå¢å¼ºç‰ˆç¼ºå¤±è¡Œé‡è¯•...")
    
    # å¯¼å…¥å¹¶è¿è¡Œé‡è¯•è„šæœ¬
    try:
        import subprocess
        
        cmd = [
            sys.executable, 'retry_missing_rows.py',
            '--csv-file', '_csvs/content_MMSafeBench_cleaned.csv',
            '--batch-dir', 'batch_results_20250525_182528',
            '--batch-size', '20',
            '--delay', '60'
        ]
        
        logger.info(f"ğŸ–¥ï¸  æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        # ä½¿ç”¨å®æ—¶è¾“å‡º
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1
        )
        
        # å®æ—¶æ˜¾ç¤ºè¾“å‡º
        while True:
            output = process.stdout.readline()
            if output == '' and process.poll() is not None:
                break
            if output:
                # ç›´æ¥æ‰“å°è¾“å‡ºï¼Œä¸é€šè¿‡loggerä»¥é¿å…é‡å¤æ ¼å¼åŒ–
                print(output.strip())
        
        return_code = process.poll()
        
        if return_code == 0:
            logger.info("âœ… ç¼ºå¤±è¡Œé‡è¯•æ‰§è¡Œå®Œæˆ")
            return True
        else:
            logger.error(f"âŒ ç¼ºå¤±è¡Œé‡è¯•æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {return_code}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        import traceback
        logger.error(f"ğŸ” å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
        return False

def show_final_summary():
    """æ˜¾ç¤ºæœ€ç»ˆæ€»ç»“"""
    logger = logging.getLogger(__name__)
    
    logger.info("="*80)
    logger.info("ğŸ“Š æ‰§è¡Œæ€»ç»“")
    logger.info("="*80)
    
    # æ£€æŸ¥ç»“æœæ–‡ä»¶
    batch_dir = "batch_results_20250525_182528"
    if os.path.exists(batch_dir):
        import glob
        result_files = glob.glob(os.path.join(batch_dir, "batch_results_*.jsonl"))
        logger.info(f"ğŸ“„ ç”Ÿæˆçš„ç»“æœæ–‡ä»¶æ•°: {len(result_files)}")
        
        # æ£€æŸ¥çŠ¶æ€æ–‡ä»¶
        status_file = os.path.join(batch_dir, "batch_status.json")
        if os.path.exists(status_file):
            try:
                import json
                with open(status_file, 'r') as f:
                    status_data = json.load(f)
                
                total_jobs = status_data.get('total_jobs', 0)
                completed_jobs = len([job for job in status_data.get('jobs', []) if job.get('status') == 'completed'])
                failed_jobs = len([job for job in status_data.get('jobs', []) if job.get('status') in ['failed', 'timeout']])
                
                logger.info(f"ğŸ“ˆ ä»»åŠ¡ç»Ÿè®¡:")
                logger.info(f"  - æ€»ä»»åŠ¡æ•°: {total_jobs}")
                logger.info(f"  - å·²å®Œæˆ: {completed_jobs}")
                logger.info(f"  - å¤±è´¥/è¶…æ—¶: {failed_jobs}")
                logger.info(f"  - å®Œæˆç‡: {completed_jobs/total_jobs*100:.1f}%" if total_jobs > 0 else "  - å®Œæˆç‡: 0%")
                
            except Exception as e:
                logger.warning(f"âš ï¸  æ— æ³•è¯»å–çŠ¶æ€æ–‡ä»¶: {e}")
    
    logger.info("ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
    logger.info("  1. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶äº†è§£è¯¦ç»†æ‰§è¡Œæƒ…å†µ")
    logger.info("  2. å¦‚æœ‰å¤±è´¥ä»»åŠ¡ï¼Œå¯ä»¥é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
    logger.info("  3. æ‰§è¡Œåˆå¹¶è„šæœ¬æ•´åˆæ‰€æœ‰ç»“æœ")
    logger.info("  4. éªŒè¯æœ€ç»ˆè¾“å‡ºæ–‡ä»¶çš„å®Œæ•´æ€§")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ å¢å¼ºç‰ˆç¼ºå¤±è¡Œé‡è¯•è„šæœ¬")
    print("="*80)
    
    # è®¾ç½®å¢å¼ºæ—¥å¿—
    logger = setup_enhanced_logging()
    
    try:
        # æ£€æŸ¥ç¯å¢ƒ
        if not check_environment():
            logger.error("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œé€€å‡º")
            return 1
        
        # æ˜¾ç¤ºæ‰§è¡Œè®¡åˆ’
        show_execution_plan()
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­
        response = input("\nğŸ¤” æ˜¯å¦å¼€å§‹æ‰§è¡Œï¼Ÿ(y/N): ")
        if response.lower() != 'y':
            logger.info("ğŸ›‘ ç”¨æˆ·å–æ¶ˆæ‰§è¡Œ")
            return 0
        
        # æ‰§è¡Œé‡è¯•
        success = run_enhanced_retry()
        
        # æ˜¾ç¤ºæ€»ç»“
        show_final_summary()
        
        if success:
            logger.info("ğŸ‰ æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæˆ")
            return 0
        else:
            logger.error("ğŸ’¥ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
            return 1
            
    except KeyboardInterrupt:
        logger.warning("âš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        return 1
    except Exception as e:
        logger.error(f"ğŸ’¥ ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°æœªé¢„æœŸçš„é”™è¯¯: {e}")
        import traceback
        logger.error(f"ğŸ” é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
