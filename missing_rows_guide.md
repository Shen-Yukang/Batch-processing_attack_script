# 缺失行重试指南

## 问题分析

根据您的项目检查，发现以下情况：

1. **批处理目录**: `batch_results_20250525_182528`
2. **缺失行文件**: `missing_rows.txt` (包含301个缺失行)
3. **配置问题**: 批处理器配置的CSV文件 `_csvs/content_CogAgent.csv` 不存在
4. **实际数据**: 从批处理输入文件看，这是图片+文本的处理任务

## 解决方案

我已经为您创建了专门的重试脚本 `retry_missing_rows.py`，它会：

1. **自动检测正确的CSV文件**
2. **智能分组缺失行**（相近的行号会分在同一批次）
3. **创建专门的批处理输入文件**
4. **提供详细的进度报告**
5. **支持失败后继续处理**

## 使用方法

### 方法1: 自动检测（推荐）

```bash
python retry_missing_rows.py
```

这会：
- 自动使用最新的批处理目录 `batch_results_20250525_182528`
- 自动检测正确的CSV文件
- 使用默认的 `missing_rows.txt` 文件

### 方法2: 指定参数

```bash
python retry_missing_rows.py \
  --batch-dir batch_results_20250525_182528 \
  --missing-file missing_rows.txt \
  --csv-file _csvs/content_MMSafeBench_cleaned.csv \
  --batch-size 20 \
  --delay 60
```

## 参数说明

- `--batch-dir`: 批处理结果目录
- `--missing-file`: 缺失行文件路径
- `--csv-file`: 指定CSV文件（可选，会自动检测）
- `--batch-size`: 每批次处理的行数（默认20）
- `--delay`: 批次间延迟秒数（默认60）

## 脚本特性

### 1. 智能批次分组
- 相近的行号（差距≤5）会分在同一批次
- 避免创建过多小批次
- 提高处理效率

### 2. 自动CSV检测
- 从现有批处理输入文件分析数据格式
- 自动查找可能的CSV文件
- 支持手动指定

### 3. 容错处理
- 跳过不存在的图片文件
- 处理图片编码错误
- 支持批次失败后继续

### 4. 详细报告
- 显示每个批次的处理进度
- 提供成本估算
- 生成最终处理总结

## 预期输出

脚本运行时会显示：

```
2025-05-25 21:45:00 - INFO - 从 missing_rows.txt 读取到 301 个缺失行
2025-05-25 21:45:00 - INFO - 找到CSV文件: _csvs/content_MMSafeBench_cleaned.csv
2025-05-25 21:45:00 - INFO - 成功加载CSV文件，共 1257 行
2025-05-25 21:45:00 - INFO - 将缺失行分为 16 个智能批次进行处理
2025-05-25 21:45:00 - INFO - 批次 1: 行号 81-100 (共20行)
2025-05-25 21:45:00 - INFO - 批次 2: 行号 161-180 (共20行)
...

准备处理 16 个批次，共 301 行。是否继续？(y/N): y
```

## 处理完成后

成功处理后，您可以运行合并脚本更新最终输出：

```bash
python merge_all_results.py batch_results_20250525_182528 _csvs/content_MMSafeBench_cleaned.csv final_output.csv
```

## 故障排除

### 1. CSV文件检测失败
如果自动检测失败，手动指定：
```bash
python retry_missing_rows.py --csv-file _csvs/content_MMSafeBench_cleaned.csv
```

### 2. 图片文件不存在
脚本会自动跳过不存在的图片文件并记录警告

### 3. 批次处理失败
脚本会询问是否继续处理下一批次，您可以选择继续或停止

## 注意事项

1. **API配额**: 确保您的OpenAI账户有足够的配额
2. **网络连接**: 确保网络连接稳定
3. **磁盘空间**: 确保有足够的磁盘空间存储结果
4. **处理时间**: 301行大约需要1-2小时处理完成

## 下一步

处理完成后，建议：

1. 检查处理结果
2. 运行合并脚本
3. 验证最终输出文件
4. 如有必要，重新运行失败的批次
